#!/usr/bin/perl -w

# -----------------------------------------------------------------
# Name:      mklex5a.pl
# Author:    Kiduk Yang, 4/29/2008
#            modified, 6/24/2008
#              - uses 2006 & 2007 qrels
#              - bug fix: line 424
#             $Id: mklex5a.pl,v 1.1 2008/06/27 00:42:31 kiyang Exp $
# -----------------------------------------------------------------
# Description:  compute opinion probabilities of lexicon terms
#   1. op_P = p(t/opD) * p (!t/nopD)
#             p(t/opD) prob that term will occur in opinion doc 
#              = df w/ t in opD / #opD
#             p(!t/nopD) prob that term will occur in opinion doc
#              = df w/o t in nopD / #nopD
# -----------------------------------------------------------------
# Argument:  arg1= 1 to run
# Input:     
#   $ddir/trainData/dnref_op - docID to blogID mapping (opinion blog)
#       DOCN TREC_DOCN REL (per line)
#   $ddir/trainData/op/docx2/$docn - processed opinion blog file (after NR & sentence break)
#   $ddir/trainData/nop/docx2/$docn - processed non-opinion blog file (after NR & sentence break)
#   $ddir/lex/wilson_strongsubj.lex - type=strongsubj (TERM PORLARITY POS)
#   $ddir/lex/wilson_weaksubj.lex   - type=weaksubj (TERM PORLARITY POS)
#   $ddir/lex/wilson_emp.lex        - emphasis lexicon (TERM)
#   $pdir/IU2.lst                   - IU lexicon
#   $pdir/HF2.lst                   - HF lexicon
#   $pdir/LF2.lst                   - LF lexicon
#   $pdir/LF2.rgx                   - LF regex
#   $pdir/LF2mrp.rgx                - LF morph regex
#   $pdir/AC.list                   - AC lexicon
# Output:   
#   $ddir/lex2/W1b.lst - type=strongsubj (TERM PORLARITY POS)
#   $ddir/lex2/W2b.lst   - type=weaksubj (TERM PORLARITY POS)
#   $ddir/lex2/EMPb.lst        - emphasis lexicon (TERM)
#   $ddir/lex2/IU3b.lst                   - IU lexicon
#   $ddir/lex2/HF3b.lst                   - HF lexicon
#   $ddir/lex2/LF3b.lst                   - LF lexicon
#   $ddir/lex2/LF3b.rgx                   - LF regex
#   $ddir/lex2/LF3mrpb.rgx                - LF morph regex
#   $pdir/lex2/AC2b.list                   - AC lexicon
#   $prog        -- program     (optional)
#   $prog.log    -- program log (optional)
# -----------------------------------------------------------------
# NOTE: uses clean training data generated by mklex2.pl
# -----------------------------------------------------------------

use strict;
use Data::Dumper;
$Data::Dumper::Purity=1;

my ($debug,$filemode,$filemode2,$dirmode,$dirmode2,$author,$group);
my ($log,$logd,$sfx,$noargp,$append,@start_time);

$log=1;                              # program log flag
$debug=0;                            # debug flag
$filemode= 0640;                     # to use w/ perl chmod
$filemode2= 640;                     # to use w/ system chmod
$dirmode= 0750;                      # to use w/ perl mkdir
$dirmode2= 750;                      # to use w/ system chmod (directory)
$group= "trec";                      # group ownership of files
$author= "kiyang\@indiana.edu";      # author's email


#------------------------
# global variables
#------------------------

my $wpdir=  "/u0/widit/prog";           # widit program directory
my $tpdir=  "$wpdir/trec08";            # TREC program directory
my $pdir=   "$tpdir/blog";              # Blog track program directory
my $pdir0=  "$wpdir/trec07/blog";       # Blog track program directory
my $ddir=   "/u3/trec/blog07";          # TREC index directory
my $ddir2=  "/u3/trec/blog08";          # TREC index directory
my $qdir=   "$ddir2/query";              # query directory

my $qryTdir=   "$qdir/train";        # processed query directory
my $qryEdir=   "$qdir/test";        # processed query directory
my $qryTdir2= "$qryTdir/s0x";         # web-expanded query phrases
my $qryEdir2= "$qryEdir/s0x";         # web-expanded query phrases

my $qrelTf=  "/u1/trec/qrels/qrels.blog06";
my $qrelEf=  "/u1/trec/qrels/07.qrels.opinion";

my $odir= "$ddir/lex2";
my $opdir= "$ddir/trainData/op/docx";    # clean opinion training data
my $nopdir= "$ddir/trainData/nop/docx";  # non-opinion training data
my $opdir2= "$ddir/trainData/op2/docx";    # clean opinion training data
my $nopdir2= "$ddir/trainData/nop2/docx";  # non-opinion training data

my $dnref_op= "$ddir/trainData/dnref_op";
my $dnref_nop= "$ddir/trainData/dnref_nop";
my $dnref_op2= "$ddir/trainData/dnref_op2";
my $dnref_nop2= "$ddir/trainData/dnref_nop2";

# input files
my $subj1f= "$ddir/lex/wilson_strongsubj.lex"; # strong subj. lexicon
my $subj2f= "$ddir/lex/wilson_weaksubj.lex";   # strong subj. lexicon
my $empf=   "$ddir/lex/wilson_emp.lex";        # emphasis lexicon
my $IUlexf= "$pdir0/IU2.list";                  # IU lexicon file
my $HFlexf= "$pdir0/HF2.list";                  # HF lexicon file
my $LFlexf= "$pdir0/LF2.list";                  # LF lexicon file
my $LFrgxf= "$pdir0/LF2.rgx";                   # LF regex file
my $LFmrpf= "$pdir0/LF2mrp.rgx";                # LF morph regex file
my $AClexf= "$pdir0/AC.list";                   # AC lexicon file

# output files
my $w1out= "$odir/W1b.list";
my $w2out= "$odir/W2b.list";
my $emout= "$odir/EMb.list";
my $iuout= "$odir/IU3b.list";                  # IU lexicon file
my $hfout= "$odir/HF3b.list";                  # HF lexicon file
my $lfout= "$odir/LF3b.list";                  # LF lexicon file
my $lfrout="$odir/LF3b.rgx";                   # LF regex file
my $lfmout="$odir/LF3mrpb.rgx";                # LF morph regex file
my $acout= "$odir/AC2b.list";                   # AC lexicon file

`mkdir -p $odir` if (!-e $odir);

require "$wpdir/logsub2.pl";   # subroutine library
require "$pdir/blogsub.pl";   # blog subroutine library


#------------------------
# program arguments
#------------------------
my $prompt=
"arg1= 1 to run\n";

my %valid_args= (
0 => " 1 ",
);

my ($arg_err,$arg1)= chkargs($prompt,\%valid_args,1);
die "$arg_err\n" if ($arg_err);


#-------------------------------------------------
# start program log
#-------------------------------------------------

$sfx= "";              # program log file suffix
$noargp=1;             # if 1, do not print arguments to log
$append=0;             # log append flag

if ($log) {
    @start_time= &begin_log($odir,$filemode,$sfx,$noargp,$append);
    print LOG "INF = $opdir/*\n",
              "      $nopdir/*\n",
              "      $opdir2/*\n",
              "      $nopdir2/*\n",
              "OUTD= $odir/\n\n";
}


#--------------------------------------------------------------------
# create the lexicon hashes
#--------------------------------------------------------------------
# %IUlex:   IU phrases
#   k(I|my|me -> term) = v($pol$sc)
# %HFlex:   HF terms
#   k(term) = v($pol$sc)
# %LFlex:   LF terms
#   k(term) = v($pol$sc)
# %LFrgx:   LF regexes
#   k(regex) = v($pol$sc)
# @LFrgx:   LF regexes
# @LFrgxsc: LF regexes scores
# %LFmrp:   LF morphed term regexes
#   k(regex) = v($pol$sc)
# @LFmrp:   LF morphed term regexes
# @LFmrpsc: LF morphed term scores
# %AClex:   Acronyms
#   k(acryonym|expanded AC) = v($pol$sc)
# %W1lex:   Wilson's strong subjective terms
#   k(term) = v($pol$sc)
# %W2lex:   Wilson's weak subjective terms
#   k(term) = v($pol$sc)
# %emplex:  Wilson's emphasis terms
#   k(term) = v($pol$sc)
#--------------------------------------------------------------------

my %IUlex;
&mkIUhash($IUlexf,\%IUlex,0);

my %IUlex2;
foreach my $iu(keys %IUlex) {
    foreach my $wd(keys %{$IUlex{$iu}}) {
        $IUlex2{$wd}++;
    }
}

my %HFlex;
&mkHFhash($HFlexf,\%HFlex);

my %LFlex;
&mkLFhash2($LFlexf,\%LFlex);
    
my (%LFrgx,@LFrgx,@LFrgxsc);
&mkLFhash1($LFrgxf,\%LFrgx,\@LFrgx,\@LFrgxsc);

my (%LFmrp,@LFmrp,@LFmrpsc);
&mkLFhash1($LFmrpf,\%LFmrp,\@LFmrp,\@LFmrpsc);

my %AClex; 
&mkAChash($AClexf,\%AClex);

my %w1lex;
&mkWhash2($subj1f,\%w1lex);

my %w2lex;
&mkWhash2($subj2f,\%w2lex);

my %emplex;
&mkWhash2($empf,\%emplex,0,0,'m1');


#-------------------------------------------------
# create hash of query terms
#-------------------------------------------------
# %qterm:  
#   k(QN -> term) = v(freq)
#-------------------------------------------------

my %qterm;
&mkQRYhash($qryTdir,$qryTdir2,\%qterm);
&mkQRYhash($qryEdir,$qryEdir2,\%qterm);

if ($debug>1) {
    foreach my $qn(sort keys %qterm) {
        print "QN=$qn\n";
        foreach my $k(sort keys %{$qterm{$qn}}) { print "   $k: $qterm{$qn}{$k}\n"; }
        print "\n";
    }
}


#-------------------------------------------------
# read in qrels file to create %qrels
#   k=blogID, v=array of QNs
#-------------------------------------------------
open(IN,$qrelTf) || die "can't read $qrelTf";
my @lines=<IN>;
close IN;
chomp @lines;

my (%qrel);
foreach (@lines) {
    my($qn,$dummy,$id,$rel)=split/ +/;
    next if ($rel<1);
    push(@{$qrel{$id}},$qn);
}


open(IN,$qrelEf) || die "can't read $qrelEf";
@lines=<IN>;
close IN;
chomp @lines;

foreach (@lines) {
    my($qn,$dummy,$id,$rel)=split/ +/;
    next if ($rel<1);
    push(@{$qrel{$id}},$qn);
}


#-------------------------------------------------
# create %dnref
#   - k=blogID, v=DN
#-------------------------------------------------
open(IN,$dnref_op) || die "can't read $dnref_op";
@lines=<IN>;
close IN;
chomp @lines;

my ($opn,%dnref_op)=(0);
foreach (@lines) {
    my($dn,$id,$rel)=split/ /;
    $dnref_op{$dn}=$id;
    $opn++;
}

open(IN,$dnref_op2) || die "can't read $dnref_op2";
@lines=<IN>;
close IN;
chomp @lines;

my ($opn2,%dnref_op2)=(0);
foreach (@lines) {
    my($dn,$id,$rel)=split/ /;
    $dnref_op2{$dn}=$id;
    $opn2++;
}


open(IN,$dnref_nop) || die "can't read $dnref_nop";
@lines=<IN>;
close IN;
chomp @lines;

my ($nopn,%dnref_nop)=(0);
foreach (@lines) {
    my($dn,$id,$rel)=split/ /;
    $dnref_nop{$dn}=$id;
    $nopn++;
}


open(IN,$dnref_nop2) || die "can't read $dnref_nop2";
@lines=<IN>;
close IN;
chomp @lines;

my ($nopn2,%dnref_nop2)=(0);
foreach (@lines) {
    my($dn,$id,$rel)=split/ /;
    $dnref_nop2{$dn}=$id;
    $nopn2++;
}


#-------------------------------------------------
# 1. process non-opinion training data
# 2. compute term frequencies
#    - { term => op|nop => df }
#-------------------------------------------------

my (%HF,%LF,%LFr,%LFm,%AC,%W1,%W2,%EM,%IU);

my $opcnt=0;
for(my $i=1; $i<=$opn; $i++) {
    my $inf="$opdir/$i";

    my %qwd;
    foreach my $qn(@{$qrel{$dnref_op{$i}}}) {
        foreach my $wd(keys %{$qterm{$qn}}) {
            $qwd{$wd}++;
        }
    }

    open(IN,$inf) || die "can't read $inf";
    my @lines=<IN>;
    close IN;

    my %goodL;  # good line numbers
    for(my $i=0; $i<@lines; $i++) {
        my $found=0;
        foreach my $wd(keys %qwd) {
            if ($lines[$i]=~/\b$wd\b/i) { 
                $found=1;
                last;
            }
        }
        if ($found) { 
            for(my $k=$i-2;$k<=$i+2;$k++) { 
                last if ($k<0 || $k>=@lines); 
                $goodL{$k}++;
            }
            $i+=2;
        }
    }

    # treat each sentence as document
    foreach my $k(keys %goodL) {
        &cntDF($lines[$k],'op');
        $opcnt++;
    }

}

for(my $i=1; $i<=$opn2; $i++) {
    my $inf="$opdir2/$i";

    my %qwd;
    foreach my $qn(@{$qrel{$dnref_op2{$i}}}) {
        foreach my $wd(keys %{$qterm{$qn}}) {
            $qwd{$wd}++;
        }
    }

    open(IN,$inf) || die "can't read $inf";
    my @lines=<IN>;
    close IN;

    my %goodL;  # good line numbers
    for(my $i=0; $i<@lines; $i++) {
        my $found=0;
        foreach my $wd(keys %qwd) {
            if ($lines[$i]=~/\b$wd\b/i) { 
                $found=1;
                last;
            }
        }
        if ($found) { 
            for(my $k=$i-2;$k<=$i+2;$k++) { 
                last if ($k<0 || $k>=@lines); 
                $goodL{$k}++;
            }
            $i+=2;
        }
    }

    # treat each sentence as document
    foreach my $k(keys %goodL) {
        &cntDF($lines[$k],'op');
        $opcnt++;
    }

}


#-------------------------------------------------
# 1. process non-opinion training data
# 2. compute term frequencies
#    - { term => op|nop => df }
#-------------------------------------------------

my $nopcnt=0;
for(my $i=1; $i<=$nopn; $i++) {
    my $inf="$nopdir/$i";

    my %qwd;
    foreach my $qn(@{$qrel{$dnref_nop{$i}}}) {   ##!! bug fix: used to be dnref_op
        foreach my $wd(keys %{$qterm{$qn}}) {
            $qwd{$wd}++;
        }
    }


    open(IN,$inf) || die "can't read $inf";
    my @lines=<IN>;
    close IN;

    my %goodL;  # good line numbers
    for(my $i=0; $i<@lines; $i++) {
        my $found=0;
        foreach my $wd(keys %qwd) {
            if ($lines[$i]=~/\b$wd\b/i) { 
                $found=1;
                last;
            }
        }
        if ($found) { 
            for(my $k=$i-2;$k<=$i+2;$k++) { 
                last if ($k<0 || $k>=@lines); 
                $goodL{$k}++;
            }
            $i+=2;
        }
    }

    # treat each sentence as document
    foreach my $k(keys %goodL) {
        &cntDF($lines[$k],'nop');
        $nopcnt++;
    }

}

for(my $i=1; $i<=$nopn2; $i++) {
    my $inf="$nopdir2/$i";

    my %qwd;
    foreach my $qn(@{$qrel{$dnref_nop2{$i}}}) {
        foreach my $wd(keys %{$qterm{$qn}}) {
            $qwd{$wd}++;
        }
    }


    open(IN,$inf) || die "can't read $inf";
    my @lines=<IN>;
    close IN;

    my %goodL;  # good line numbers
    for(my $i=0; $i<@lines; $i++) {
        my $found=0;
        foreach my $wd(keys %qwd) {
            if ($lines[$i]=~/\b$wd\b/i) { 
                $found=1;
                last;
            }
        }
        if ($found) { 
            for(my $k=$i-2;$k<=$i+2;$k++) { 
                last if ($k<0 || $k>=@lines); 
                $goodL{$k}++;
            }
            $i+=2;
        }
    }

    # treat each sentence as document
    foreach my $k(keys %goodL) {
        &cntDF($lines[$k],'nop');
        $nopcnt++;
    }

}

print LOG "Documents: $opn Positive, $nopn Negative\n",
          "Sentences: $opcnt Positive, $nopcnt Negative\n\n";

&mkLex($hfout,\%HF);
&mkLex($iuout,\%IU);
&mkLex($acout,\%AC);
&mkLex($w1out,\%W1);
&mkLex($w2out,\%W2);
&mkLex($emout,\%EM);
&mkLex($lfout,\%LF);
&mkLex($lfrout,\%LFr);
&mkLex($lfmout,\%LFm);


#-------------------------------------------------
# end program
#-------------------------------------------------

&end_log($pdir,$odir,$filemode,@start_time) if ($log);

# notify author of program completion
#&notify($sfx,$author);


##############################################
# SUBROUTINES
##############################################

BEGIN { print STDOUT "\n"; }
END { print STDOUT "\n"; }

#-------------------------------------------------
# count DF
#-------------------------------------------------
#  arg1 = text string
#  arg2 = DF type (op, nop)
#-------------------------------------------------
sub cntDF {
    my ($text,$type)=@_;

    # split words by space, hyphen, multiple comma/period
    $text=~s/[,\.]{2,}/ /g;
    my @wds= split/[\s\-]+/,lc($text);

    my %words;

    foreach my $wd(@wds) {
        next if ($wd=~/\W/);
        $words{$wd}=1;
    }

    foreach my $wd(keys %words) {
        $HF{$wd}{$type}++ if ($HFlex{$wd});
        $AC{$wd}{$type}++ if ($AClex{$wd});
        $W1{$wd}{$type}++ if ($w1lex{$wd});
        $W2{$wd}{$type}++ if ($w2lex{$wd});
        $EM{$wd}{$type}++ if ($emplex{$wd});
        $IU{$wd}{$type}++ if ($IUlex2{$wd});
        $LF{$wd}{$type}++ if ($LFlex{$wd});
        foreach my $rgx(keys %LFrgx) {
            $LFr{$rgx}{$type}++ if ($wd=~/$rgx/i);
        }
        foreach my $mrp(keys %LFmrp) {
            $LFm{$mrp}{$type}++ if ($wd=~/$mrp/i);
        }
    }

} #endsub cntDF


#-------------------------------------------------
# ouput updated lexicon file
#-------------------------------------------------
#  arg1 = filename
#  arg2 = hptr to lexicon hash
#-------------------------------------------------
sub mkLex {
    my($outf,$lexhp)=@_;

    open(OUT,">$outf") || die "can't write to $outf";
    print LOG " - Writing to $outf\n";

    foreach my $wd(keys %$lexhp) {
        $lexhp->{$wd}{'op'}=0 if (!$lexhp->{$wd}{'op'});
        $lexhp->{$wd}{'nop'}=0 if (!$lexhp->{$wd}{'nop'});
    }

    foreach my $wd(sort {$lexhp->{$b}{'op'}<=>$lexhp->{$a}{'op'}} keys %$lexhp) {
        my $op=$lexhp->{$wd}{'op'};
        my $nop=$lexhp->{$wd}{'nop'};
        my $p= (($op+1)/($opcnt+2))*(($nopcnt-$nop+1)/($nopcnt+2));
        printf OUT "$wd %.4f $op $nop\n",$p;
    }

    close OUT;
    print LOG "\n";

}

    
#-------------------------------------------------
# create hashes of query text
#   - qdesc2, phrase, nr_phrase, nr_nouns should not be used for short query runs
#-------------------------------------------------
#  arg1 = processed query directory
#  arg2 = webx query phrases directory
#  arg3 = pointer to query title hash
#           k= QN, v= query title text (raw)
#  arg4 = pointer to processed query title hash
#           k= QN, v= query title text (stopped & stemmed)
#  arg5 = pointer to processed query description hash
#           k= QN, v= query description text (stopped & stemmed)
#  arg6 = pointer to processed query phrase hash
#           k= QN, v= hash pointer
#             k= phrase, v= freq
#  arg7 = pointer to expanded query phrase hash
#           k= QN, v= hash pointer
#             k= phrase, v= freq
#  arg8 = pointer to processed query non-relevant phrase hash
#           k= QN, v= hash pointer
#             k= nonrel_phrase, v= freq
#  arg9 = pointer to processed query non-relevant noun hash
#           k= QN, v= hash pointer
#             k= nonrel_noun, v= freq
#-------------------------------------------------
sub mkQRYhash {
    my($in,$in2,$hp)=@_;
            
    opendir(IND,$in) || die "can't opendir $in";
    my @files= readdir(IND);
    closedir IND;
        
    foreach my $file(@files) {
            
        next if ($file!~/^q(\d+)/);
        my $qn=$1;
                    
        # get expanded noun phrases
        my $inf2="$in2/qsx$qn";
        open(IN2,$inf2) || die "can't read $inf2";
        while(<IN2>) {
            chomp;
            my($wd,$wt)=split/ +/;
            $hp->{$qn}{lc($wd)}=1;
        }   
        close IN2;
            
        my $inf="$in/$file";
        open(IN,$inf) || die "can't read $inf";
        my @lines=<IN>;
        close IN;

        my $bstring= join("",@lines);

        # get title text
        if ($bstring=~m|<title>(.+?)</title>|s) {
            my $str=$1;
            $str=~m|<text>(.+?)</text>\n<text0>(.+?)</text0>|s;
            my ($ti,$ti2)=($1,$2);

            # delete quotations & punctuations
            $ti=~s/"//g;
            $ti=~s/^\W*(.+?)\W*$/$1/g;

            # accomodate (Boolean) OR in title text
            $ti=~s/\s*OR\s*/ /g if ($ti=~/^(.+?)\s+OR\b/);

            # accomodate changes in indexing module (7/20/2007)
            $ti2=$1 if ($ti2=~/^(.+?)\s+,/);

            foreach my $wd(split/ +/,"$ti $ti2") {
                $hp->{$qn}{lc($wd)}=1;
            }
        }

        # get description text
        if ($bstring=~m|<desc>(.+?)</desc>|s) {
            my $str=$1;
            $str=~m|<text0>(.+?)</text0>|s;
            my $desc=$1;

            # accomodate changes in indexing module (7/20/2007)
            $desc=$1 if ($desc=~/^(.+?)\s+,/);
            foreach my $wd(split/ +/,$desc) {
                $hp->{$qn}{lc($wd)}=1;
            }
        }

        # get noun phrases
        if (my @text= $bstring=~m|<phrase>(.+?)</phrase>|gs) {
            my %wds;
            foreach my $str(@text) {
                my @wds=split(/ +/,$str);
                foreach my $wd(@wds) {
                    $hp->{$qn}{lc($wd)}=1;
                }
            }
        }

    } #end-foreach $file(@files) 

} #endsub mkQRYhash

